import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from typing import Dict, List, Optional
import json
import os

class GPTExploitGenerator:
    def __init__(self, model_name: str = "gpt2"):
        """Initialize the GPT-based exploit generator with safety controls."""
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        
        # Load target whitelist for safety
        self.target_whitelist = self._load_target_whitelist()
        
        # Template for exploit generation
        self.exploit_template = """
Vulnerability Analysis:
{vuln_description}

Target System:
{target_info}

Required Components:
- Entry point: {entry_point}
- Vulnerability type: {vuln_type}
- Attack vector: {attack_vector}

Generate a proof-of-concept exploit that:
1. Validates the vulnerability
2. Implements safety checks
3. Includes error handling
4. Avoids harmful payload execution
"""

    def _load_target_whitelist(self) -> Dict:
        """Load the whitelist of allowed targets."""
        whitelist_path = "/home/ubuntu/target_whitelist.json"
        try:
            with open(whitelist_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            print(f"Warning: Could not load target whitelist: {e}")
            return {}

    def _validate_target(self, target_info: Dict) -> bool:
        """Validate if the target is in the whitelist."""
        if not self.target_whitelist:
            return False
        
        target_id = target_info.get('id')
        return target_id in self.target_whitelist

    def _prepare_prompt(self, vulnerability_details: Dict) -> str:
        """Prepare the prompt for exploit generation."""
        return self.exploit_template.format(
            vuln_description=vulnerability_details.get('description', ''),
            target_info=vulnerability_details.get('target', {}),
            entry_point=vulnerability_details.get('entry_point', 'Unknown'),
            vuln_type=vulnerability_details.get('type', 'Unknown'),
            attack_vector=vulnerability_details.get('vector', 'Unknown')
        )

    def _validate_generated_code(self, code: str) -> bool:
        """Validate generated exploit code for safety."""
        forbidden_patterns = [
            "rm -rf",
            "format",
            "mkfs",
            "dd if=",
            ":(){ :|:& };:",
            "> /dev/sda",
            "shutdown",
            "reboot"
        ]
        
        return not any(pattern in code.lower() for pattern in forbidden_patterns)

    def generate_exploit(self, 
                        vulnerability_details: Dict,
                        max_length: int = 1024,
                        temperature: float = 0.7,
                        top_p: float = 0.9) -> Optional[str]:
        """
        Generate an exploit based on vulnerability details.
        
        Args:
            vulnerability_details: Dictionary containing vulnerability information
            max_length: Maximum length of generated text
            temperature: Controls randomness (higher = more random)
            top_p: Controls diversity via nucleus sampling
            
        Returns:
            Generated exploit code or None if validation fails
        """
        # Validate target first
        if not self._validate_target(vulnerability_details.get('target', {})):
            print("Error: Target validation failed - not in whitelist")
            return None

        # Prepare the prompt
        prompt = self._prepare_prompt(vulnerability_details)
        
        # Generate exploit code
        inputs = self.tokenizer.encode(prompt, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                inputs,
                max_length=max_length,
                temperature=temperature,
                top_p=top_p,
                num_return_sequences=1,
                pad_token_id=self.tokenizer.eos_token_id,
                do_sample=True
            )
        
        generated_code = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Validate generated code
        if not self._validate_generated_code(generated_code):
            print("Error: Generated code validation failed - potentially unsafe content")
            return None
            
        return generated_code

    def update_learning(self, 
                       vulnerability_details: Dict,
                       generated_exploit: str,
                       success: bool,
                       feedback: str = "") -> None:
        """
        Update the model's learning based on exploit success/failure.
        Implements reinforcement learning and pattern extraction.
        
        Args:
            vulnerability_details: Original vulnerability information
            generated_exploit: The generated exploit code
            success: Whether the exploit was successful
            feedback: Additional feedback for learning
        """
        if not hasattr(self, 'learning_history'):
            self.learning_history = {
                'successful_patterns': {},
                'failed_patterns': {},
                'generation_params': {},
                'success_rate': {}
            }
        
        vuln_type = vulnerability_details.get('type', 'unknown')
        
        # Initialize type-specific tracking if needed
        if vuln_type not in self.learning_history['successful_patterns']:
            self.learning_history['successful_patterns'][vuln_type] = []
            self.learning_history['failed_patterns'][vuln_type] = []
            self.learning_history['success_rate'][vuln_type] = []
            self.learning_history['generation_params'][vuln_type] = {
                'temperature': 0.7,
                'top_p': 0.9,
                'success_count': 0,
                'total_count': 0
            }
        
        # Extract code patterns
        patterns = self._extract_patterns(generated_exploit)
        
        # Update pattern history based on success
        if success:
            self.learning_history['successful_patterns'][vuln_type].extend(patterns)
            self.learning_history['generation_params'][vuln_type]['success_count'] += 1
        else:
            self.learning_history['failed_patterns'][vuln_type].extend(patterns)
        
        self.learning_history['generation_params'][vuln_type]['total_count'] += 1
        
        # Calculate success rate
        params = self.learning_history['generation_params'][vuln_type]
        success_rate = params['success_count'] / params['total_count']
        self.learning_history['success_rate'][vuln_type].append(success_rate)
        
        # Adjust generation parameters based on success rate
        self._adjust_generation_params(vuln_type, success_rate)
        
        # Prune old patterns to maintain memory efficiency
        self._prune_patterns(vuln_type)
    
    def _extract_patterns(self, code: str) -> List[str]:
        """Extract useful patterns from generated code."""
        patterns = []
        lines = code.split('\n')
        
        current_block = []
        for line in lines:
            if line.strip():
                current_block.append(line)
            elif current_block:
                if len(current_block) >= 2:  # Only keep meaningful blocks
                    patterns.append('\n'.join(current_block))
                current_block = []
        
        # Add final block if exists
        if current_block and len(current_block) >= 2:
            patterns.append('\n'.join(current_block))
        
        return patterns
    
    def _adjust_generation_params(self, vuln_type: str, success_rate: float) -> None:
        """Adjust generation parameters based on success rate."""
        params = self.learning_history['generation_params'][vuln_type]
        
        # Adjust temperature based on success rate
        if success_rate < 0.3:
            # Lower temperature for more focused generation
            params['temperature'] = max(0.3, params['temperature'] - 0.1)
        elif success_rate > 0.7:
            # Increase temperature for more exploration
            params['temperature'] = min(1.0, params['temperature'] + 0.1)
        
        # Adjust top_p based on success rate
        if success_rate < 0.3:
            # Lower top_p for more conservative sampling
            params['top_p'] = max(0.5, params['top_p'] - 0.1)
        elif success_rate > 0.7:
            # Increase top_p for more diverse sampling
            params['top_p'] = min(1.0, params['top_p'] + 0.1)
    
    def _prune_patterns(self, vuln_type: str, max_patterns: int = 1000) -> None:
        """Prune old patterns to maintain memory efficiency."""
        for pattern_type in ['successful_patterns', 'failed_patterns']:
            patterns = self.learning_history[pattern_type][vuln_type]
            if len(patterns) > max_patterns:
                # Keep most recent patterns
                self.learning_history[pattern_type][vuln_type] = patterns[-max_patterns:]

    def get_generation_metrics(self) -> Dict:
        """Get metrics about the exploit generation process."""
        return {
            "model_name": self.model.config.name_or_path,
            "device": str(self.device),
            "vocab_size": self.model.config.vocab_size,
            "max_position_embeddings": self.model.config.max_position_embeddings,
        }
