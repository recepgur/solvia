import json
import os
import time
from datetime import datetime

import pandas as pd
import requests


class ExploitDBCollector:
    def __init__(self):
        self.base_url = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
        self.max_retries = 3
        self.retry_delay = 5  # seconds
        self.headers = {"User-Agent": "SecurityResearchBot/1.0"}
        self.data = []

    def fetch_exploits(self):
        """Fetch exploit data from Exploit-DB's GitHub repository"""
        print("Downloading Exploit-DB database...")

        for attempt in range(self.max_retries):
            try:
                # Download the CSV file
                print(f"Attempt {attempt + 1}/{self.max_retries}...")
                response = requests.get(self.base_url, headers=self.headers, timeout=30)

                if response.status_code == 200:
                    # Save temporary CSV
                    temp_file = "temp_exploitdb.csv"
                    with open(temp_file, "wb") as f:
                        f.write(response.content)

                    # Read CSV with proper columns
                    df = pd.read_csv(temp_file)

                    # Process each exploit
                    for _, row in df.iterrows():
                        exploit_data = {
                            "id": f"EDB-{row['id']}",
                            "published": row["date_published"],
                            "description": row["description"],
                            "type": row["type"],
                            "platform": row["platform"],
                            "author": row["author"],
                            "port": row["port"],
                            "source": "exploit-db",
                            "verified": row["verified"],
                            "codes": row["codes"],
                            "tags": row["tags"],
                        }

                        self.data.append(exploit_data)

                    # Clean up temporary file
                    os.remove(temp_file)
                    print(f"Successfully collected {len(self.data)} exploits")
                    return len(self.data)

                else:
                    print(
                        f"Error downloading Exploit-DB database: {response.status_code}"
                    )
                    if attempt < self.max_retries - 1:
                        print(f"Retrying in {self.retry_delay} seconds...")
                        time.sleep(self.retry_delay)
                        continue
                    return 0

            except Exception as e:
                print(f"Error: {str(e)}")
                if attempt < self.max_retries - 1:
                    print(f"Retrying in {self.retry_delay} seconds...")
                    time.sleep(self.retry_delay)
                    continue
                return 0

        return 0  # If all retries failed

    def save_to_csv(self, filename="exploitdb_dataset.csv"):
        """Save collected data to CSV"""
        df = pd.DataFrame(self.data)
        df.to_csv(filename, index=False)
        print(f"Saved {len(df)} exploits to {filename}")

    def get_dataset(self):
        """Return the collected data as a pandas DataFrame"""
        return pd.DataFrame(self.data)


if __name__ == "__main__":
    collector = ExploitDBCollector()
    print("Fetching exploit data from Exploit-DB...")
    count = collector.fetch_exploits()
    print(f"\nTotal exploits fetched: {count}")
    collector.save_to_csv()
